---
title: "Confidence Intervals"
subtitle: "In-Class Activity"
author: "PUT YOUR NAME HERE"
date: 'Last rendered on `r format(Sys.time(), "%A, %B %d, %Y @ %I:%M %p")`'
output: 
  html_document: 
    theme: yeti
    highlight: textmate
    toc: true
    toc_depth: 5
    toc_float: false
---
***

```{r globaloptions, include = FALSE}
# this sets the options but is not shown in the render
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
```

### Packages Used

```{r packages_used}
library(tidyverse) # for manipulation
library(moderndive) # for bowl sample 
library(moments) # for skew and kurt
library(infer) # for bootstrapping
library(knitr) # needed for kable()
library(kableExtra) # for styling
```

### CI for One Proportion

This portion is based on the example found in in [Section 8.5.1](https://moderndive.com/8-confidence-intervals.html#ilyas-yohan) of *Modern Dive*. The sample is in the dataset `bowl_sample` found in the **moderndive** package.

#### Compute the Statistic from the Sample

What is the sample proportion of red balls $\hat{p}$?

```{r}
p_hat <- bowl_sample_1 %>% 
  specify(response = color, success = "red") %>% 
  calculate(stat = "prop")
p_hat
```

#### Create the Sampling Distribution

Use bootstrapping methods to simulate the sampling distribution of $\hat{p}$?

```{r}
bootstrap_distribution <- bowl_sample_1 %>% 
  specify(response = color, success = "red") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "prop")
bootstrap_distribution
```

#### Visualize the Distribution

If we want to use a bootstrap SE interval, the distribution must be approximately normal. 

##### Histogram, Skewness, and Kurtosis

Does the distribution deviate from approximate normality, based on the histogram, skewness, and excess kurtosis?

```{r}
visualize(bootstrap_distribution) +
  labs(x = "statistic = p-hat")
```

```{r}
bootstrap_distribution %>% 
  summarize(skew   = skewness(stat),
            exkurt = kurtosis(stat) - 3)
```

##### Normal Quantile-Quantile Plot

Does the distribution deviate from approximate normality, based on the QQ plot?

```{r}
ggplot(bootstrap_distribution, aes(sample = stat)) +
  geom_qq() +
  geom_qq_line(color = "blue")
```

#### Compute the 95% Percentile Interval

Whether or not the distribution is approximately normal, we can compute a bootstrap percentile interval for $\hat{p}$ as long as we have a reasonably representative sample. Since this is a random sample, the probability is high that it is representative.

```{r}
percentile_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "percentile")
percentile_ci
```

#### Compute the 95% Standard Error (SE) Interval

Let's go ahead and try computing the bootstrap SE interval for $\hat{p}$.

```{r}
standard_error_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "se", point_estimate = p_hat)
standard_error_ci
```

#### Visualize the Intervals

We can visualize each interval alone, or put both on the same plot to compare. 

```{r}
visualize(bootstrap_distribution) +
  labs(x = "statistic = p-hat") +
  shade_confidence_interval(endpoints = percentile_ci,
                            color = "coral",
                            fill = "lightcoral") +
  shade_confidence_interval(endpoints = standard_error_ci,
                            color = "skyblue",
                            fill = "lightskyblue",
                            alpha = 0.5) # transparency (0 to 1)
```

#### Traditional Confidence Interval

If the assumptions of the Central Limit Theorem are met, a traditional confidence interval is an option. Let's see how it compares to the bootstrap intervals.

```{r}
z <- 1.96

n <- bowl_sample_1 %>% 
  filter(!is.na(color)) %>%  
  summarize(length(color)) %>%
  pull()

p_hat_est <- pull(p_hat)

traditional_ci <- p_hat_est + c(-1,1) * z * sqrt(p_hat_est * (1 - p_hat_est) / n)
```

#### Whis is the best interval to use?

Let's compare the three intervals. Is there a difference?

```{r}
rbind(percentile_ci,
      standard_error_ci,
      tibble(lower_ci = traditional_ci[1],
             upper_ci = traditional_ci[2])) %>% 
  mutate(interval = c("Percentile", "Standard Error", "Traditional"),
         width = upper_ci - lower_ci) %>% 
  relocate(interval, .before = lower_ci) %>% 
  kable(digits = 4,
        col.names = c("Interval Type", "Lower Bound", "Upper Bound", "Width"),
        align = c("l", "c", "c"),
        caption = "Interval Estimate Comparison and Precision") %>% 
  kable_styling(full_width = FALSE,
                position = "left",
                font_size = 14)
  
```

#### Do the intervals contain the population proportion?

For this problem, we have the luxury of knowing the population proportion. Is that value in your intervals? If not, does that mean you did something wrong?

```{r}
pop_p <- bowl %>% 
  summarize(p_red = mean(color == "red"))
pop_p
```

### Let's Experiment!

#### CI for a Proportion: Change Confidence

Experiment with different levels of confidence for `bowl_sample_1`. How does this affect the width of the CI?

```{r}

```

#### CI for a Proportion: Larger Sample Size

Experiment with different sample sizes for `bowl_sample_1` (up to n = 240). How does this affect the width of the CI?

```{r}

```

### Is Yawning Contagious?

This portion is based on the example found in in [Section 8.6]https://moderndive.com/8-confidence-intervals.html#case-study-two-prop-ci) of *Modern Dive*. The sample is in the dataset `mythbusters_yawn` found in the **moderndive** package.

#### Summarize the Data

```{r}
mythbusters_yawn %>% 
  group_by(group) %>% 
  count(yawn) %>% 
  mutate(p_hat = prop.table(n))
```

```{r}
obs_diff_in_p_hats <- mythbusters_yawn %>% 
  specify(formula = yawn ~ group, success = "yes") %>% 
  # generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "diff in props", order = c("seed", "control"))
obs_diff_in_p_hats
```

#### Sampling Distribution and Interval

```{r}
bootstrap_distribution_yawning <- mythbusters_yawn %>% 
  specify(formula = yawn ~ group, success = "yes") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "diff in props", order = c("seed", "control"))
bootstrap_distribution_yawning
```

```{r}
visualize(bootstrap_distribution_yawning) +
  geom_vline(xintercept = 0, color = "blue", size = 2)
```

```{r}
myth_percentile_ci <- bootstrap_distribution_yawning %>% 
  get_confidence_interval(type = "percentile", level = 0.95)
myth_percentile_ci
```

```{r}
myth_se_ci <- bootstrap_distribution_yawning %>% 
  get_confidence_interval(type = "se", point_estimate = obs_diff_in_p_hats)
myth_se_ci
```

```{r}

```

***
```{r}
sessionInfo()
```
