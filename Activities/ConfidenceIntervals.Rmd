---
title: "Confidence Intervals"
subtitle: "In-Class Activity"
author: "PUT YOUR NAME HERE"
date: 'Last rendered on `r format(Sys.time(), "%A, %B %d, %Y @ %I:%M %p")`'
output: 
  html_document: 
    theme: yeti
    highlight: textmate
    toc: true
    toc_depth: 5
    toc_float: false
---
***

```{r globaloptions, include = FALSE}
# this sets the options but is not shown in the render
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
```

### Packages Used

```{r packages_used}
library(tidyverse) # for manipulation
library(moderndive) # for bowl sample 
library(moments) # for skew and kurt
library(infer) # for bootstrapping
library(knitr) # needed for kable()
library(kableExtra) # for styling
```

### CI for One Proportion

This portion is based on the example found in in [Section 8.5.1](https://moderndive.com/8-confidence-intervals.html#ilyas-yohan) of *Modern Dive*. The sample is in the dataset `bowl_sample` found in the **moderndive** package.

#### Compute the Statistic from the Sample

What is the sample proportion of red balls $\hat{p}$?

Recall, p-hat is our point estimate of p, the true population proportion.

```{r}
p_hat <- bowl_sample_1 %>%                        # sample dataset
  specify(response = color, success = "red") %>%  # specify the variable, red = success
  calculate(stat = "prop")                        # calculate sample proportion of red
p_hat
```

#### Create the Sampling Distribution

Use bootstrapping methods to simulate the sampling distribution of $\hat{p}$?

We are assuming that this sample is representative of the population. Since it's a random sample from the population, it probably is. (we can never be certain, we have to use logic and knowledge of how it was collected)

```{r}
bootstrap_distribution <- bowl_sample_1 %>% 
  specify(response = color, success = "red") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "prop")
bootstrap_distribution
```

#### Visualize the Distribution

If we want to use a bootstrap SE interval (or a traditional interval), the distribution must be approximately normal. For a percentile interval, it doesn't matter what shape it is.

##### Histogram, Skewness, and Kurtosis

Does the distribution deviate from approximate normality, based on the histogram, skewness, and excess kurtosis? If it doesn't deviate too much, we can call it approximately normal.

```{r}
visualize(bootstrap_distribution) + # default is 15 bins
  labs(x = "statistic = p-hat (sample proportion of red balls)")

visualize(bootstrap_distribution, bins = 12) +
  labs(x = "statistic = p-hat (sample proportion of red balls)")
```

```{r}
ggplot(bootstrap_distribution, aes(stat)) +
  geom_density()
```

```{r}
bootstrap_distribution %>% 
  summarize(skew   = skewness(stat),
            exkurt = kurtosis(stat) - 3)
```

##### Normal Quantile-Quantile Plot

Does the distribution deviate from approximate normality, based on the QQ plot?

```{r}
ggplot(bootstrap_distribution, aes(sample = stat)) +
  geom_qq() +
  geom_qq_line(color = "blue")
```

#### Compute the 95% Percentile Interval

Whether or not the distribution is approximately normal, we can compute a bootstrap percentile interval for $\hat{p}$ as long as we have a reasonably representative sample. Since this is a random sample, the probability is high that it is representative.

The margin of error (precision) depends on n (sample size) and p-hat (sample proportion) and level of confidence. We also learned that confidence intervals tend to be widest when p = 0.5.

```{r}
percentile_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "percentile") # quantile method
percentile_ci
```

#### Compute the 95% Standard Error (SE) Interval

Let's go ahead and try computing the bootstrap SE interval for $\hat{p}$. Remember, this is a mash-up of the traditional CI and bootstrap methods.

point estimate (from data) +/- ME (from the bootstrap sampling dist)

p_hat +/- 1.96 * SE_bootstrap (for 95% confidence)

```{r}
standard_error_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "se", point_estimate = p_hat)
standard_error_ci
```

#### Visualize the Intervals

We can visualize each interval alone, or put both on the same plot to compare. 

The "green" area covers the middle 95% of the bootstrap distribution.

Our percentile interval does not have the form point estimate +/- margin of error (i.e., ME)

```{r}
visualize(bootstrap_distribution) +
  labs(x = "statistic = p-hat (sample proportion of red balls)") +
  shade_confidence_interval(endpoints = percentile_ci) + # the stored percentile interval
  geom_vline(xintercept = pull(p_hat), size = 2)
```

```{r}
visualize(bootstrap_distribution) +
  labs(x = "statistic = p-hat (sample proportion of red balls)") +
  shade_confidence_interval(endpoints = standard_error_ci) + # the stored SE interval
  geom_vline(xintercept = pull(p_hat), size = 2)
```

```{r}
visualize(bootstrap_distribution) +
  labs(x = "statistic = p-hat") +
  shade_confidence_interval(endpoints = percentile_ci,
                            color = "coral",
                            fill = "lightcoral") +
  shade_confidence_interval(endpoints = standard_error_ci,
                            color = "skyblue",
                            fill = "lightskyblue",
                            alpha = 0.5) + # transparency (0 to 1)
  geom_vline(xintercept = pull(p_hat), size = 2)
```

#### Traditional Confidence Interval

If the assumptions of the Central Limit Theorem are met, a traditional confidence interval is an option. Let's see how it compares to the bootstrap intervals.

We can only do this if the assumptions of the CLT are met. Remember, for proportions...

n * p >= 10 and n * p * (1-p) >= 10

```{r}
p <- pull(p_hat)
n <- 50

n * p >= 10
n * p * (1 - p) >= 10
```

We also visually assessed approximate normality above. We also have an independent random sample. And we have less than 10% of the population.

```{r}
z <- 1.96 # for 95% confidence use 1.96

n <- bowl_sample_1 %>% 
  filter(!is.na(color)) %>%  
  summarize(length(color)) %>%
  pull()

p_hat_est <- pull(p_hat)

traditional_ci <- p_hat_est + c(-1,1) * z * sqrt(p_hat_est * (1 - p_hat_est) / n)
traditional_ci
```

#### Whis is the best interval to use?

Let's compare the three intervals. Is there a difference?

```{r}
rbind(percentile_ci,
      standard_error_ci,
      tibble(lower_ci = traditional_ci[1],
             upper_ci = traditional_ci[2])) %>% 
  mutate(interval = c("Percentile", "Standard Error", "Traditional"),
         width = upper_ci - lower_ci) %>% 
  relocate(interval, .before = lower_ci) %>% 
  kable(digits = 4,
        col.names = c("Interval Type", "Lower Bound", "Upper Bound", "Width"),
        align = c("l", "c", "c"),
        caption = "Interval Estimate Comparison and Precision") %>% 
  kable_styling(full_width = FALSE,
                position = "left",
                font_size = 14)
  
```

#### Do the intervals contain the population proportion?

For this problem, we have the luxury of knowing the population proportion. Is that value in your intervals? If not, does that mean you did something wrong?

```{r}
pop_p <- bowl %>% 
  summarize(p_red = mean(color == "red"))
pop_p
```

### Let's Experiment!

#### CI for a Proportion: Change Confidence

Experiment with different levels of confidence for `bowl_sample_1`. How does this affect the width of the CI?

```{r}

```

#### CI for a Proportion: Larger Sample Size

Experiment with different sample sizes for `bowl_sample_1` (up to n = 240). How does this affect the width of the CI?

```{r}

```

### Is Yawning Contagious?

This portion is based on the example found in in [Section 8.6]https://moderndive.com/8-confidence-intervals.html#case-study-two-prop-ci) of *Modern Dive*. The sample is in the dataset `mythbusters_yawn` found in the **moderndive** package.

#### Summarize the Data

```{r}
mythbusters_yawn %>% 
  group_by(group) %>% 
  count(yawn) %>% 
  mutate(p_hat = prop.table(n))
```

```{r}
obs_diff_in_p_hats <- mythbusters_yawn %>% 
  specify(formula = yawn ~ group, success = "yes") %>% 
  # generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "diff in props", order = c("seed", "control"))
obs_diff_in_p_hats
```

#### Sampling Distribution and Interval

```{r}
bootstrap_distribution_yawning <- mythbusters_yawn %>% 
  specify(formula = yawn ~ group, success = "yes") %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "diff in props", order = c("seed", "control"))
bootstrap_distribution_yawning
```

```{r}
visualize(bootstrap_distribution_yawning) +
  geom_vline(xintercept = 0, color = "blue", size = 2)
```

```{r}
myth_percentile_ci <- bootstrap_distribution_yawning %>% 
  get_confidence_interval(type = "percentile", level = 0.95)
myth_percentile_ci
```

```{r}
myth_se_ci <- bootstrap_distribution_yawning %>% 
  get_confidence_interval(type = "se", point_estimate = obs_diff_in_p_hats)
myth_se_ci
```

```{r}

```

***
```{r}
sessionInfo()
```